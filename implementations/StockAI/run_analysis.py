#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
run_analysis.py
ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

ì‹¤í–‰ ìˆœì„œ:
1. ì¼ë³„ ì‹œì„¸ ìˆ˜ì§‘ (create_complete_daily_prices.py)
2. ê¸°ê´€/ì™¸êµ­ì¸ ìˆ˜ê¸‰ ë¶„ì„ (all_institutional_trend_data.py)
3. íŒŒë™ ë¶„ì„ ë° ë“±ê¸‰ ì‚°ì¶œ (analysis2.py)
4. AI ì‹¬ì¸µ ë¶„ì„ (investigate_top_stocks.py) - ì„ íƒ

ì‚¬ìš©ë²•:
    python run_analysis.py           # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    python run_analysis.py --quick   # ë¹ ë¥¸ ì—…ë°ì´íŠ¸ (ì˜¤ëŠ˜ ë°ì´í„°ë§Œ)
    python run_analysis.py --skip-ai # AI ë¶„ì„ ê±´ë„ˆë›°ê¸°
"""

import os
import sys
import time
import subprocess
import argparse
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ìƒìˆ˜ ì •ì˜
BASE_DIR = os.path.dirname(os.path.abspath(__file__))


def run_script(script_name: str, args: list = None, timeout: int = 600) -> bool:
    """
    Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        script_name: ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ëª…
        args: ì¶”ê°€ ì¸ì ë¦¬ìŠ¤íŠ¸
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    script_path = os.path.join(BASE_DIR, script_name)
    
    if not os.path.exists(script_path):
        logger.error(f"Script not found: {script_path}")
        return False
    
    cmd = [sys.executable, script_path]
    if args:
        cmd.extend(args)
    
    logger.info(f"Running: {script_name}")
    start_time = time.time()
    
    try:
        result = subprocess.run(
            cmd,
            timeout=timeout,
            capture_output=True,
            text=True,
            cwd=BASE_DIR
        )
        
        elapsed = time.time() - start_time
        
        if result.returncode == 0:
            logger.info(f"âœ… {script_name} completed in {elapsed:.1f}s")
            return True
        else:
            logger.error(f"âŒ {script_name} failed:")
            logger.error(result.stderr)
            return False
            
    except subprocess.TimeoutExpired:
        logger.error(f"âŒ {script_name} timed out after {timeout}s")
        return False
    except Exception as e:
        logger.error(f"âŒ {script_name} error: {e}")
        return False


def run_full_pipeline(quick_update: bool = False, skip_ai: bool = False, top_n: int = 10):
    """
    ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        quick_update: ë¹ ë¥¸ ì—…ë°ì´íŠ¸ ëª¨ë“œ (ì˜¤ëŠ˜ ë°ì´í„°ë§Œ)
        skip_ai: AI ë¶„ì„ ê±´ë„ˆë›°ê¸°
        top_n: AI ë¶„ì„í•  ìƒìœ„ ì¢…ëª© ìˆ˜
    """
    logger.info("=" * 60)
    logger.info("ğŸ¥ StockAI Analysis Pipeline Started")
    logger.info(f"   Mode: {'Quick Update' if quick_update else 'Full Analysis'}")
    logger.info(f"   AI Analysis: {'Disabled' if skip_ai else 'Enabled'}")
    logger.info(f"   Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    total_start = time.time()
    results = {}
    
    # Step 1: ì¼ë³„ ì‹œì„¸ ìˆ˜ì§‘
    logger.info("\nğŸ“Š Step 1/6: Collecting Daily Prices...")
    price_args = ['--update'] if quick_update else ['--days', '365']
    results['prices'] = run_script('create_complete_daily_prices.py', price_args, timeout=1200)

    if not results['prices']:
        logger.error("Price collection failed. Aborting pipeline.")
        return results

    # Step 2: ê¸°ê´€/ì™¸êµ­ì¸ ìˆ˜ê¸‰ ë¶„ì„
    logger.info("\nğŸ’° Step 2/6: Analyzing Institutional Trends...")
    results['institutional'] = run_script('all_institutional_trend_data.py', timeout=900)

    # Step 3: íŒŒë™ ë¶„ì„
    logger.info("\nğŸŒŠ Step 3/6: Running Wave Analysis...")
    results['analysis'] = run_script('analysis2.py', timeout=300)
    
    if not results['analysis']:
        logger.error("Wave analysis failed. Skipping AI investigation.")
        skip_ai = True
    
    # Step 4: AI ì‹¬ì¸µ ë¶„ì„ (ì„ íƒ)
    if not skip_ai:
        logger.info("\nğŸ¤– Step 4/6: AI Deep Investigation...")
        ai_args = ['--top', str(top_n)]
        results['ai'] = run_script('investigate_top_stocks.py', ai_args, timeout=600)
    else:
        logger.info("\nâ­ï¸ Step 4/6: AI Analysis Skipped")
        results['ai'] = None

    # Step 5: ì„±ê³¼ ì¶”ì  - ì¶”ì²œ ì €ì¥
    logger.info("\nğŸ“ˆ Step 5/6: Saving Recommendations to History...")
    try:
        from track_performance import PerformanceTracker
        tracker = PerformanceTracker()
        saved_file = tracker.save_recommendations()
        results['tracking'] = bool(saved_file)
        if saved_file:
            logger.info(f"   Saved to: {saved_file}")
    except Exception as e:
        logger.warning(f"   Performance tracking failed: {e}")
        results['tracking'] = False

    # Step 6: ì•Œë¦¼ ì „ì†¡ (ì„ íƒ)
    logger.info("\nğŸ“¢ Step 6/6: Sending Notifications...")
    try:
        from notifier import StockNotifier
        notifier = StockNotifier()
        if notifier.telegram.is_configured() or notifier.discord.is_configured() or notifier.slack.is_configured():
            notifier.notify_new_picks()
            results['notification'] = True
        else:
            logger.info("   No notification channels configured (skipped)")
            results['notification'] = None
    except Exception as e:
        logger.warning(f"   Notification failed: {e}")
        results['notification'] = False

    # ìš”ì•½
    total_elapsed = time.time() - total_start
    
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‹ Pipeline Summary")
    logger.info("=" * 60)
    
    for step, success in results.items():
        if success is None:
            status = "â­ï¸ Skipped"
        elif success:
            status = "âœ… Success"
        else:
            status = "âŒ Failed"
        logger.info(f"   {step.capitalize()}: {status}")
    
    logger.info(f"\n   Total Time: {total_elapsed/60:.1f} minutes")
    logger.info("=" * 60)
    
    # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    logger.info("\nğŸ¯ Next Steps:")
    logger.info("   1. View results: python -c \"import pandas as pd; print(pd.read_csv('wave_transition_analysis_results.csv').head(20))\"")
    logger.info("   2. Launch Flask dashboard: python flask_app.py  # http://localhost:5003")
    logger.info("   3. Launch Streamlit dashboard: streamlit run dashboard/app.py")
    logger.info("   4. Check performance: python track_performance.py --report")
    
    return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='StockAI Analysis Pipeline',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python run_analysis.py               # Full analysis
  python run_analysis.py --quick       # Quick update (today only)
  python run_analysis.py --skip-ai     # Skip AI analysis
  python run_analysis.py --top 20      # Analyze top 20 stocks with AI
        """
    )
    
    parser.add_argument(
        '--quick', '-q',
        action='store_true',
        help='Quick update mode (collect only recent data)'
    )
    
    parser.add_argument(
        '--skip-ai', '-s',
        action='store_true',
        help='Skip AI deep investigation'
    )
    
    parser.add_argument(
        '--top', '-t',
        type=int,
        default=10,
        help='Number of top stocks for AI analysis (default: 10)'
    )
    
    args = parser.parse_args()
    
    try:
        results = run_full_pipeline(
            quick_update=args.quick,
            skip_ai=args.skip_ai,
            top_n=args.top
        )
        
        # ì „ì²´ ì„±ê³µ ì—¬ë¶€ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ
        all_success = all(v is None or v for v in results.values())
        sys.exit(0 if all_success else 1)
        
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ Pipeline interrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nâŒ Pipeline error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
